{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DLKit Overview\n",
    "\n",
    "DLKit is a Python implementation of the OSIDs (www.osid.org). DLKit specific documentation is available at http://dlkit-doc.readthedocs.io\n",
    "\n",
    "DLKit exposes Python API bindings of the OSID service contracts, which are organized into a number of `service packages`.  Service packages describe a complete set of functionality for a particular service domain, like `assessment`, or `logging`.  These service packages define APIs that describe all the entities, or `objects` related to a particular service domain, as well as the various actions that a programmer can take on these objects. Each service defines a catalog object, which houses / contains the additional objects. In addition to aiding organization, these catalogs also help control authorization to the contained objects, and can be arranged hierarchically (with authorizations flowing down).\n",
    "\n",
    "             MIT\n",
    "            /   \\\n",
    "           /     \\\n",
    "       Physics   Math  \n",
    "\n",
    "Someone with access to all of MIT could see both Math and Physics materials, but folks in Physics may not be able to see Math materials.\n",
    "\n",
    "Let's start with a simple example and dig more in depth.\n",
    "\n",
    "Note that all data generated with this tutorial is saved in JSON files to your harddrive, in a folder called `tutorial-data`, sibling to this `.ipynb` file. If you ever want to start over, just delete that folder and all its contents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment Service\n",
    "\n",
    "In the Assessment Service, the catalog is called a `Bank`. `Banks` contain other objects, like `Items`, `Assessments`, `AssessmentsOffered`, `AssessmentsTaken`, etc. We'll start with `Item` and `Assessment`.\n",
    "\n",
    "To being with, you access the functionality of each service package through a `Manager`. For example, an `AssessmentManager` gives you access to the various methods available for accessing `Banks` and `Items`, and the other objects defined for `assessment`.\n",
    "\n",
    "In order to get a `Manager`, we go through the `runtime` -- in this tutorial, the `dlkit_edx` runtime (it's not very specific to edX, but that's what we call it). We will simulate a user and a test web request, to pass along to the service manager when its instantiated. This username is automatically available to many kinds of underlying actions and objects, such as when taking assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dlkit_edx import PROXY_SESSION, RUNTIME\n",
    "from dlkit_edx.proxy_example import TestRequest\n",
    "\n",
    "condition = PROXY_SESSION.get_proxy_condition()\n",
    "dummy_request = TestRequest(username='tutorial_user@school.edu',\n",
    "                            authenticated=True)\n",
    "condition.set_http_request(dummy_request)\n",
    "proxy = PROXY_SESSION.get_proxy(condition)\n",
    "am = RUNTIME.get_service_manager('ASSESSMENT',\n",
    "                                  proxy=proxy)\n",
    "\n",
    "print am"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Banks**\n",
    "\n",
    "Now that we have an `AssessmentManager`, we can see what `Banks` exist in the system. Calling for \"lists\" of things returns a \"thing list\", like a `BankList` (a Python generator), and we can check the number of results with `.available()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print am.banks\n",
    "print am.banks.available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No banks!! Okay, let's create one. In `DLKit`, CrUD operations are done with `forms`. So let's get a `form` to create a new assessment `bank`, and assign it a `displayName` and `description` that we'll recognize later.\n",
    "\n",
    "Notice that in the `get_bank_form_for_create()` method, we pass an empty list as an argument. This can be used to extend the base functionality of the `bank`, via record extensions. This is a more advanced feature we'll touch on in a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "form = am.get_bank_form_for_create([])\n",
    "form.display_name = \"MyBank\"\n",
    "form.description = \"For learning about DLKit\"\n",
    "bank = am.create_bank(form)\n",
    "print bank\n",
    "print bank.display_name.text\n",
    "print bank.description.text\n",
    "print str(bank.ident)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that our new `Bank` has some attributes -- some that we assigned (`display_name` and `description`, and others that were created by `DLKit`, like `ident`). `display_name` and `description` return `DisplayText` objects that include the text strings we created, but can also contain language, format, and script data, which is why we call `display_name.text` and `description.text` above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Items**\n",
    "\n",
    "Now that we have a `Bank`, we can create assessment `Items` in it. \n",
    "\n",
    "An `Item` is what you might think of as a basic assessment question with the associated answers (right or wrong). There are many types of `Item`s, including multiple choice, fill in the blank, short answer, etc.\n",
    "\n",
    "Again, we can inspect to see if any exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print bank.items\n",
    "print bank.items.available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a new item, we'll grab a form. In the `OSIDS`, since `Items` are not defined beyond a question and answer, we'll need to pass along a list of record extensions, so give the item some functionality. This requires some internal knowledge about `DLKit`, so for now well just use a simple multiple choice record plus accomodation for wrong-answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dlkit_edx.primitives import Type\n",
    "from records.registry import ITEM_RECORD_TYPES\n",
    "MULTIPLE_CHOICE_ITEM = Type(**ITEM_RECORD_TYPES['multi-choice'])\n",
    "WRONG_ANSWER_ITEM = Type(**ITEM_RECORD_TYPES['wrong-answer'])\n",
    "\n",
    "form = bank.get_item_form_for_create([MULTIPLE_CHOICE_ITEM, WRONG_ANSWER_ITEM])\n",
    "form.display_name = \"Basic addition question\"\n",
    "form.description = \"addition question with fruit\"\n",
    "item = bank.create_item(form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have now created an item, but where's the actual question that we want a student to respond to?? We'll create that separately, with its own records. Recall:\n",
    "\n",
    "        Item\n",
    "          |--Question\n",
    "          |--Answers\n",
    "          \n",
    "Since `Questions` are distinct from `Items`, students can be sent only the `Question` object, without any danger of them seeing any `answers` . Note that the `Question` `form` requires an extra `itemId` argument.  This attaches the question to the `Item` created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from records.registry import QUESTION_RECORD_TYPES\n",
    "MULTIPLE_CHOICE_QUESTION = Type(**QUESTION_RECORD_TYPES['multi-choice-text'])\n",
    "\n",
    "form = bank.get_question_form_for_create(item.ident, [MULTIPLE_CHOICE_QUESTION])\n",
    "form.set_text(\"Which color do you prefer?\")\n",
    "form.add_choice(\"blue\")\n",
    "form.add_choice(\"red\")\n",
    "form.add_choice(\"yellow\")\n",
    "question = bank.create_question(form)\n",
    "\n",
    "print question.get_choices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Item` has a method that allows us to get access to the `Question`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print item.get_question()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What?!?! Oh, wait ... because the `Item` object we have was initialized before the `Question` was actually created, we need to re-grab that `Item` to get it in the \"newest\" state. Note that this is a due to the particular service implementation we are using. Some implementations might actually keep objects up-to-date with the underlying persistence (like database or filespace) and never let an object get `stale`.  you can check if an object is known to be up-to-date with underlying data by calling it's `is_current()` method.  If it is not, you can refresh the object, in this case our `Item` by calling the `get_item(item_id)` method of the Bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print item.is_current()\n",
    "if not item.is_current()\n",
    "    item = bank.get_item(item.ident)\n",
    "print item.get_question()\n",
    "print item.get_question().get_choices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also set up wrong / right `Answers`, to be used in evaluating the \"correctness\" of the response. We indicate the type of `Answer` with the `genusTypeId` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from records.registry import ANSWER_GENUS_TYPES, ANSWER_RECORD_TYPES\n",
    "MULTIPLE_CHOICE_ANSWER = Type(**ANSWER_RECORD_TYPES['multi-choice'])\n",
    "RIGHT_ANSWER = Type(**ANSWER_GENUS_TYPES['right-answer'])\n",
    "WRONG_ANSWER = Type(**ANSWER_GENUS_TYPES['wrong-answer'])\n",
    "\n",
    "form = bank.get_answer_form_for_create(item.ident, [MULTIPLE_CHOICE_ANSWER])\n",
    "form.set_genus_type(RIGHT_ANSWER)\n",
    "# We'll just set \"blue\" as the right answer, arbitrarily\n",
    "form.add_choice_id('57fe61edcdfc5c3a0bc23b49')\n",
    "answer1 = bank.create_answer(form)\n",
    "\n",
    "form = bank.get_answer_form_for_create(item.ident, [MULTIPLE_CHOICE_ANSWER])\n",
    "form.set_genus_type(WRONG_ANSWER)\n",
    "# and \"yellow\" as the wrong answer\n",
    "form.add_choice_id('57fe61edcdfc5c3a0bc23b4b')\n",
    "answer2 = bank.create_answer(form)\n",
    "print \"done creating answers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can find the `Item` `Answers` (if you run the above block multiple times, you'll get a varying number of `Answer` elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "item = bank.get_item(item.ident)\n",
    "print item.get_answers().available()\n",
    "print [a.object_map for a in item.get_answers()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait ... where are all the wrong `Answers`? There should be 2x the number of times you ran the block, `Answers` ... and by looking at the `genusTypeId` attributes, it seems like all the `Answers` from `get_answers()` are only \"right-answer\" types.\n",
    "\n",
    "This is because `DLKit` defines the `get_answers()` method to only return the \"right\" answers, so the \"wrong\" answers need to be retrieved with a different method, defined by the `Item` record extension for wrong answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print item.get_wrong_answers().available()\n",
    "print [a.object_map for a in item.get_wrong_answers()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There they are!\n",
    "\n",
    "That's a basic overview of `Items`. They are very powerful, and to learn more, you can inspect the `records` directory that came along with this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Assessments\n",
    "\n",
    "Conceptually, `Items` are organized into `Assessments` -- which are then offered to students. An `Assessment` in a classroom might be a homework, a quiz, or an exam ... a tool that evaluates students' knowledge of a topic or outcome.\n",
    "\n",
    "Let's see what `Assessments` exist in our `Bank`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print bank.get_assessments()\n",
    "print bank.get_assessments().available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're starting with a clean slate, we have no `Assessments`. Let's get a `form`, and create one. Note that with the current `DLKit` configuration, we need to include at least the `simple-child-sequencing` record for each `Assessment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from records.registry import ASSESSMENT_RECORD_TYPES\n",
    "SIMPLE_SEQUENCE_ASSESSMENT = Type(**ASSESSMENT_RECORD_TYPES['simple-child-sequencing'])\n",
    "\n",
    "form = bank.get_assessment_form_for_create([SIMPLE_SEQUENCE_ASSESSMENT])\n",
    "form.display_name = 'Homework #1'\n",
    "form.description = 'Favorites'\n",
    "assessment = bank.create_assessment(form)\n",
    "print assessment\n",
    "print bank.get_assessment_items(assessment.ident).available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our `Assessment`, we can add `Items` to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bank.add_item(assessment.ident, item.ident)\n",
    "print bank.get_assessment_items(assessment.ident).available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great for authoring `Assessments`, but `DLKit` defines another set of methods to offer the `Assessment` in \"student mode\". This is through the `AssessmentSession` methods which define actions for taking assessments -- but first, we need to create an `AssessmentOffered`. `AssessmentsOffered` wrap some other information around the canonical `Assessment`, like the `start_time`, `deadline`, `duration`, etc. -- all of these typically are optional. Leaving them out \"opens\" the `AssessmentOffered` to students immediately, and it never \"closes\".\n",
    "\n",
    "Again, we need a `form` for this, and that method requires the `Assessment` ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "form = bank.get_assessment_offered_form_for_create(assessment.ident, [])\n",
    "assessment_offered = bank.create_assessment_offered(form)\n",
    "print assessment_offered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have an `AssessmentOffered`, we can provide a set of methods for students to take the assessment. Each \"taker\" generates an `AssessmentTaken`, which links a taker's user ID (which was provided through the `Proxy` when the `AssessmentManager` was initially set up) to the `AssessmentOffered` ID. The `AssessmentTaken` also links to one or more `AssessmentSections`, which maintains a list of questions takers have seen and thier responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "form = bank.get_assessment_taken_form_for_create(assessment_offered.ident, [])\n",
    "assessment_taken = bank.create_assessment_taken(form)\n",
    "print assessment_taken\n",
    "print str(assessment_taken.get_taking_agent_id().identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways a `taker` can get the `Assessment` questions ... they are the same for our simple `Assessment` because there is only one question, but you can easily imagine how the behavior might change when multiple questions are present. For sequential `Assessments`, each question must be answered in order. Hence, you iterate through the questions using methods like `get_first_question()` & `get_next_question()` or `get_first_unanswered_question()` & `get_next_unanswered_question()`. Alternatively, if the `Assessment` does not specify that the questions must be answered sequentially, you can get all the questions in bulk, via `get_questions()`. In more complex and adaptive scenarios, even this method might be dynamically updated, as students navigate through the `Assessment`.\n",
    "\n",
    "`Assessments` can be divided into multiple `AssessmentSections`, for example to provide UI separation. In our simple `Assessment`, there is only one `AssessmentSection`, and we'll use that ID to grab the questions.\n",
    "\n",
    "Let's demonstrate the methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assessment_section = bank.get_first_assessment_section(assessment_taken.ident)\n",
    "print str(bank.get_first_question(assessment_section.ident).ident)\n",
    "print str(bank.get_first_unanswered_question(assessment_section.ident).ident)\n",
    "print [str(q.ident) for q in bank.get_questions(assessment_section.ident)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's interesting to note that this question ID is *different* than the original `Item` ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print str(item.ident)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because questions, when put into an `AssessmentSection`, generate new, unique IDs. This helps us manage more advanced `Item` and `Question` records that manipulate the ID attribute to provide adaptability or consistent randomization -- which is beyond the scope of this basic tutorial.\n",
    "\n",
    "However, we will use this new question ID to submit a `Response`. Again, we'll use a `form`, and we'll supply it with a `choice` ID from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question = bank.get_first_question(assessment_section.ident)\n",
    "choices = question.get_choices()\n",
    "print choices\n",
    "\n",
    "form = bank.get_response_form(assessment_section.ident, question.ident)\n",
    "form.add_choice_id(choices[1]['id'])\n",
    "bank.submit_response(assessment_section.ident, question.ident, form)\n",
    "response = bank.get_response(assessment_section.ident, question.ident)\n",
    "print response.is_correct()\n",
    "print response.get_submission_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this last method, `is_correct()`, is a non-OSID convenience method, that currently only works with multiple choice questions, but can easily be integrated into any record extension.\n",
    "\n",
    "We can try submitting again, if the `AssessmentOffered` allows us to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "form = bank.get_response_form(assessment_section.ident, question.ident)\n",
    "form.add_choice_id(choices[0]['id'])\n",
    "bank.submit_response(assessment_section.ident, question.ident, form)\n",
    "response = bank.get_response(assessment_section.ident, question.ident)\n",
    "print response.is_correct()\n",
    "print response.get_submission_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that both submissions are stored in the database, but currently only the most recent one can be retrieved. Time data in `DLKit` is stored as UTC, so the information printed above may differ from your local time.\n",
    "\n",
    "At any time, instructors can get a record of all student `Responses` and questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "responses = bank.get_assessment_taken_responses(assessment_taken.ident)\n",
    "print [r.object_map for r in responses]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, the results only include the `Responses` without regard to `AssessmentSections`, but you can easily link in the actual questions as well. Sample code is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question_maps = []\n",
    "for index, question in enumerate(assessment_section.get_questions()):\n",
    "    question_map = question.object_map\n",
    "    question_map.update({\n",
    "            'itemId': assessment_section._my_map['questions'][index]['itemId'],\n",
    "            'responses': []\n",
    "        })\n",
    "    question_maps.append(question_map)\n",
    "for index, response in enumerate(responses):\n",
    "    question_maps[index]['responses'].append(response.object_map)\n",
    "print question_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we add back in the `itemId` attribute so that we can map the questions that students see (now with all unique IDs) back to the original `Items`.\n",
    "\n",
    "But, um...why is the `Responses` list empty? Because `OsidLists` are exhaustive -- they are Python generators. So they can only be iterated through once. We can solve that either by converting to a list, or calling the `get_assessment_taken_responses()` method again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "responses_list = list(bank.get_assessment_taken_responses(assessment_taken.ident))\n",
    "responses = bank.get_assessment_taken_responses(assessment_taken.ident)\n",
    "question_maps = []\n",
    "for index, question in enumerate(assessment_section.get_questions()):\n",
    "    question_map = question.object_map\n",
    "    question_map.update({\n",
    "            'itemId': assessment_section._my_map['questions'][index]['itemId'],\n",
    "            'responses': []\n",
    "        })\n",
    "    question_maps.append(question_map)\n",
    "for index, response in enumerate(responses):\n",
    "    question_maps[index]['responses'].append(response.object_map)\n",
    "print question_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you have the basics of the `Assessment` service! Much of the additional complexity appears in the record extensions for various `Item` types and `Assessment` / `AssessmentOffered` / `AssessmentTaken` settings.\n",
    "\n",
    "For example, we have randomized multiple choice questions where the choices appear in different orders to each student, but when students return to the `AssessmentTaken`, they see the exact same order they've seen before -- randomized per student, not per view of the question.\n",
    "\n",
    "Another example of a complex assessment is adaptive behavior, where the \"next question\" a student sees depends on their response to the previous question. So each students gets a different set of questions, depending on their knowledge and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Patterns in DLKit\n",
    "\n",
    "Now that we've gone through the `Assessment` service, you've hopefully learned the basics about catalogs, objects, forms, sessions, and managers. Luckily, these patterns appear across all the `DLKit` services. So you can easily pick up how to use the other services. http://osid.org/ is a good reference, and we've included a simple table below that reflects the services available in this `DLKit` build:\n",
    "\n",
    "````\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "|   Service     |      Catalog     |                            Objects                                     |\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "| Assessment    | Bank             | Item, Assessment, AssessmentOffered, AssessmentTaken, AssessmentPart   |\n",
    "| Authorization | Vault            | Authorization                                                          |\n",
    "| Commenting    | Book             | Comment                                                                |\n",
    "| Grading       | Gradebook        | GradeSystem, GradeEntry, GradebookColumn                               |\n",
    "| Logging       | Log              | LogEntry                                                               |\n",
    "| Repository    | Repository       | Asset, AssetContent, Composition                                       |\n",
    "| Resource      | Bin              | Resource                                                               |\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
