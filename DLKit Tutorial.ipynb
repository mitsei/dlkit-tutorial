{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DLKit Overview\n",
    "\n",
    "DLKit is a Python implementation of the OSIDs (www.osid.org).\n",
    "\n",
    "Every service has a catalog object, which houses / contains additional objects. These catalogs help control authorization to the contained objects, and can be arranged hierarchically (with authorizations flowing down).\n",
    "\n",
    "             MIT\n",
    "            /   \\\n",
    "           /     \\\n",
    "       Physics   Math  \n",
    "\n",
    "Someone with access to all of MIT could see both Math and Physics materials, but folks in Physics may not be able to see Math materials.\n",
    "\n",
    "Let's start with a simple example and dig more in depth.\n",
    "\n",
    "Note that all data generated with this tutorial is saved in JSON files to your harddrive, in a folder called `tutorial-data`, sibling to this `.ipynb` file. If you ever want to start over, just delete that folder and all its contents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment Service\n",
    "\n",
    "In the Assessment Service, the catalog is called a `bank`. `banks` contain other objects, called `item`, `assessment`, `assessmentOffered`, `assessmentTaken`, etc. We'll start with `item` and `assessment`.\n",
    "\n",
    "To being with, you access each service through a `manager`. For example, an `AssessmentManager` gives you access to the various `bank` and `item` methods.\n",
    "\n",
    "In order to get a `manager`, we go through the `runtime` -- in this tutorial, the `dlkit_edx` runtime (it's not very specific to edX, but that's what we call it). We will simulate a user and a test web request, to pass along. This username is automatically included with many types of data, such as when taking assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dlkit.services.assessment.AssessmentManager object at 0x10f04aa10>\n"
     ]
    }
   ],
   "source": [
    "from dlkit_edx import PROXY_SESSION, RUNTIME\n",
    "from dlkit_edx.proxy_example import TestRequest\n",
    "\n",
    "condition = PROXY_SESSION.get_proxy_condition()\n",
    "dummy_request = TestRequest(username='tutorial_user@school.edu',\n",
    "                            authenticated=True)\n",
    "condition.set_http_request(dummy_request)\n",
    "proxy = PROXY_SESSION.get_proxy(condition)\n",
    "am = RUNTIME.get_service_manager('ASSESSMENT',\n",
    "                                  proxy=proxy)\n",
    "\n",
    "print am"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Banks**\n",
    "\n",
    "Now that we have an `AssessmentManager`, we can see what `banks` exist in the system. Calling for \"lists\" of things returns a \"thing list\", like a `BankList` (a Python generator), and we can check the number of results with `.available()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dlkit.services.assessment.BankList object at 0x10e781490>\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print am.banks\n",
    "print am.banks.available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No banks!! Okay, let's create one. In `DLKit`, CRUD operations are done with `forms`. So let's get a `form` to create a new assessment `bank`, and assign it a `displayName` and `description` that we'll recognize later.\n",
    "\n",
    "Notice that in the `get_bank_form_for_create()` method, we pass an empty list as an argument. This can be used to extend the base functionality of the `bank`, via record extensions. That is a more advanced feature we'll touch on later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dlkit.services.assessment.Bank object at 0x10f04a410>\n",
      "MyBank\n",
      "For learning about DLKit\n",
      "assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU\n"
     ]
    }
   ],
   "source": [
    "form = am.get_bank_form_for_create([])\n",
    "form.display_name = \"MyBank\"\n",
    "form.description = \"For learning about DLKit\"\n",
    "bank = am.create_bank(form)\n",
    "print bank\n",
    "print bank.display_name.text\n",
    "print bank.description.text\n",
    "print str(bank.ident)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that our new `bank` has some attributes -- some that we assigned (`displayName` and `description`, and others that were created by `DLKit`, like `ident`). `displayName` and `description` are actually objects themselves, and can also contain language, format, and script data, which is why we call `display_name.text` and `description.text` above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Items**\n",
    "\n",
    "Now that we have a `bank`, we can create assessment `items` in it. \n",
    "\n",
    "An `item` is what you might think of as a basic assessment question with the associated answers (right or wrong). There are many types of `item`s, including multiple choice, fill in the blank, short answer, etc.\n",
    "\n",
    "Again, we can inspect to see if any exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dlkit.mongo.assessment.objects.ItemList object at 0x10f27d8d0>\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print bank.items\n",
    "print bank.items.available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a new item, we'll grab a form. In the `OSIDS`, since `items` are not defined beyond a question and answer, we'll need to pass along a list of record extensions, so give the item some functionality. This requires some internal knowledge about `DLKit`, so for now well just use a simple multiple choice record plus accomodation for wrong-answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dlkit_edx.primitives import Type\n",
    "from records.registry import ITEM_RECORD_TYPES\n",
    "MULTIPLE_CHOICE_ITEM = Type(**ITEM_RECORD_TYPES['multi-choice'])\n",
    "WRONG_ANSWER_ITEM = Type(**ITEM_RECORD_TYPES['wrong-answer'])\n",
    "\n",
    "form = bank.get_item_form_for_create([MULTIPLE_CHOICE_ITEM, WRONG_ANSWER_ITEM])\n",
    "form.display_name = \"Basic addition question\"\n",
    "form.description = \"addition question with fruit\"\n",
    "item = bank.create_item(form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But where's the question?? We'll create that separately, with its own records. Recall:\n",
    "\n",
    "        Item\n",
    "          |--Question\n",
    "          |--Answers\n",
    "          \n",
    "Since `questions` are distinct from `items`, students can be sent only the `question` object, without any danger of `answers` leaking. Note that the `question` `form` requires an extra `itemId` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'blue', 'id': '57fe61edcdfc5c3a0bc23b49', 'name': ''}, {'text': 'red', 'id': '57fe61edcdfc5c3a0bc23b4a', 'name': ''}, {'text': 'yellow', 'id': '57fe61edcdfc5c3a0bc23b4b', 'name': ''}]\n"
     ]
    }
   ],
   "source": [
    "from records.registry import QUESTION_RECORD_TYPES\n",
    "MULTIPLE_CHOICE_QUESTION = Type(**QUESTION_RECORD_TYPES['multi-choice-text'])\n",
    "\n",
    "form = bank.get_question_form_for_create(item.ident, [MULTIPLE_CHOICE_QUESTION])\n",
    "form.set_text(\"Which color do you prefer?\")\n",
    "form.add_choice(\"blue\")\n",
    "form.add_choice(\"red\")\n",
    "form.add_choice(\"yellow\")\n",
    "question = bank.create_question(form)\n",
    "\n",
    "print question.get_choices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `item` also has a handle to its own `question`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8a6fa2760d7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/cjshaw/Documents/Projects/CLIx/dlkit-tutorial/dlkit/mongo/assessment/objects.py\u001b[0m in \u001b[0;36mget_question\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    442\u001b[0m         return Question(osid_object_map=self._my_map['question'],\n\u001b[1;32m    443\u001b[0m                         \u001b[0mruntime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_runtime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                         proxy=self._proxy)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_question\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cjshaw/Documents/Projects/CLIx/dlkit-tutorial/dlkit/mongo/assessment/objects.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mosid_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOsidObject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'QUESTION'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_catalog_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bank'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'item_id'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cjshaw/Documents/Projects/CLIx/dlkit-tutorial/dlkit/mongo/osid/objects.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, osid_object_map, runtime, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mosid_markers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtensible\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mruntime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_my_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mosid_object_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosid_object_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recordTypeIds'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_object_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "print item.get_question()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What?!?! Oh, wait ... because the `item` object we have was initialized before the `question` was actually created, we need to re-grab that `item` to get it in the \"newest\" state. Note that you can also get the same information by calling `is_current()` on the item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "<dlkit.mongo.assessment.objects.Question object at 0x10f6023d0>\n",
      "[{u'text': u'blue', u'id': u'57fe61edcdfc5c3a0bc23b49', u'name': u''}, {u'text': u'red', u'id': u'57fe61edcdfc5c3a0bc23b4a', u'name': u''}, {u'text': u'yellow', u'id': u'57fe61edcdfc5c3a0bc23b4b', u'name': u''}]\n"
     ]
    }
   ],
   "source": [
    "print item.is_current()\n",
    "item = bank.get_item(item.ident)\n",
    "print item.get_question()\n",
    "print item.get_question().get_choices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also set up wrong / right `answers`, to be used in evaluating the \"correctness\" of the response. We indicate the type of `answer` with the `genusTypeId` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done creating answers\n"
     ]
    }
   ],
   "source": [
    "from records.registry import ANSWER_GENUS_TYPES, ANSWER_RECORD_TYPES\n",
    "MULTIPLE_CHOICE_ANSWER = Type(**ANSWER_RECORD_TYPES['multi-choice'])\n",
    "RIGHT_ANSWER = Type(**ANSWER_GENUS_TYPES['right-answer'])\n",
    "WRONG_ANSWER = Type(**ANSWER_GENUS_TYPES['wrong-answer'])\n",
    "\n",
    "form = bank.get_answer_form_for_create(item.ident, [MULTIPLE_CHOICE_ANSWER])\n",
    "form.set_genus_type(RIGHT_ANSWER)\n",
    "# We'll just set \"blue\" as the right answer, arbitrarily\n",
    "form.add_choice_id('57fe61edcdfc5c3a0bc23b49')\n",
    "answer1 = bank.create_answer(form)\n",
    "\n",
    "form = bank.get_answer_form_for_create(item.ident, [MULTIPLE_CHOICE_ANSWER])\n",
    "form.set_genus_type(WRONG_ANSWER)\n",
    "# and \"yellow\" as the wrong answer\n",
    "form.add_choice_id('57fe61edcdfc5c3a0bc23b4b')\n",
    "answer2 = bank.create_answer(form)\n",
    "print \"done creating answers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can find the `item` `answers` (if you run the above block multiple times, you'll get a varying number of `answer` elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[{u'displayName': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'description': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'recordTypeIds': [u'answer-record-type%3Amulti-choice%40ODL.MIT.EDU'], 'bankId': u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU', u'choiceIds': [u'57fe61edcdfc5c3a0bc23b49'], u'genusTypeId': 'answer-type%3Aright-answer%40ODL.MIT.EDU', u'assignedBankIds': [u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU'], 'type': 'Answer', 'id': 'assessment.Answer%3A57fe6605cdfc5c3a0bc23b4c%40ODL.MIT.EDU'}, {u'displayName': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'description': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'recordTypeIds': [u'answer-record-type%3Amulti-choice%40ODL.MIT.EDU'], 'bankId': u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU', u'choiceIds': [u'57fe61edcdfc5c3a0bc23b49'], u'genusTypeId': 'answer-type%3Aright-answer%40ODL.MIT.EDU', u'assignedBankIds': [u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU'], 'type': 'Answer', 'id': 'assessment.Answer%3A57fe660dcdfc5c3a0bc23b4d%40ODL.MIT.EDU'}, {u'displayName': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'description': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'recordTypeIds': [u'answer-record-type%3Amulti-choice%40ODL.MIT.EDU'], 'bankId': u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU', u'choiceIds': [u'57fe61edcdfc5c3a0bc23b49'], u'genusTypeId': 'answer-type%3Aright-answer%40ODL.MIT.EDU', u'assignedBankIds': [u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU'], 'type': 'Answer', 'id': 'assessment.Answer%3A57fe6655cdfc5c3a0bc23b4f%40ODL.MIT.EDU'}, {u'displayName': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'description': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'recordTypeIds': [u'answer-record-type%3Amulti-choice%40ODL.MIT.EDU'], 'bankId': u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU', u'choiceIds': [u'57fe61edcdfc5c3a0bc23b49'], u'genusTypeId': 'answer-type%3Aright-answer%40ODL.MIT.EDU', u'assignedBankIds': [u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU'], 'type': 'Answer', 'id': 'assessment.Answer%3A57fe66c9cdfc5c3a0bc23b51%40ODL.MIT.EDU'}, {u'displayName': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'description': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'recordTypeIds': [u'answer-record-type%3Amulti-choice%40ODL.MIT.EDU'], 'bankId': u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU', u'choiceIds': [u'57fe61edcdfc5c3a0bc23b49'], u'genusTypeId': 'answer-type%3Aright-answer%40ODL.MIT.EDU', u'assignedBankIds': [u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU'], 'type': 'Answer', 'id': 'assessment.Answer%3A57fe6865cdfc5c3a0bc23b53%40ODL.MIT.EDU'}]\n"
     ]
    }
   ],
   "source": [
    "item = bank.get_item(item.ident)\n",
    "print item.get_answers().available()\n",
    "print [a.object_map for a in item.get_answers()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait ... where are all the wrong `answers`? There should be 2x the number of times you ran the block, `answers` ... and by looking at the `genusTypeId` attributes, it seems like all the `answers` from `get_answers()` are \"right-answer\" types.\n",
    "\n",
    "This is because `DLKit` defines the `get_answers()` method to only return the \"right\" answers, so the \"wrong\" answers need to be retrieved with a different method, defined by the `item` record extension for wrong answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[{u'displayName': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'description': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'recordTypeIds': [u'answer-record-type%3Amulti-choice%40ODL.MIT.EDU'], 'bankId': u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU', u'choiceIds': [u'57fe61edcdfc5c3a0bc23b4b'], u'genusTypeId': 'answer-type%3Awrong-answer%40ODL.MIT.EDU', u'assignedBankIds': [u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU'], 'type': 'Answer', 'id': 'assessment.Answer%3A57fe660dcdfc5c3a0bc23b4e%40ODL.MIT.EDU'}, {u'displayName': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'description': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'recordTypeIds': [u'answer-record-type%3Amulti-choice%40ODL.MIT.EDU'], 'bankId': u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU', u'choiceIds': [u'57fe61edcdfc5c3a0bc23b4b'], u'genusTypeId': 'answer-type%3Awrong-answer%40ODL.MIT.EDU', u'assignedBankIds': [u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU'], 'type': 'Answer', 'id': 'assessment.Answer%3A57fe6655cdfc5c3a0bc23b50%40ODL.MIT.EDU'}, {u'displayName': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'description': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'recordTypeIds': [u'answer-record-type%3Amulti-choice%40ODL.MIT.EDU'], 'bankId': u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU', u'choiceIds': [u'57fe61edcdfc5c3a0bc23b4b'], u'genusTypeId': 'answer-type%3Awrong-answer%40ODL.MIT.EDU', u'assignedBankIds': [u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU'], 'type': 'Answer', 'id': 'assessment.Answer%3A57fe66c9cdfc5c3a0bc23b52%40ODL.MIT.EDU'}, {u'displayName': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'description': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'recordTypeIds': [u'answer-record-type%3Amulti-choice%40ODL.MIT.EDU'], 'bankId': u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU', u'choiceIds': [u'57fe61edcdfc5c3a0bc23b4b'], u'genusTypeId': 'answer-type%3Awrong-answer%40ODL.MIT.EDU', u'assignedBankIds': [u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU'], 'type': 'Answer', 'id': 'assessment.Answer%3A57fe6865cdfc5c3a0bc23b54%40ODL.MIT.EDU'}]\n"
     ]
    }
   ],
   "source": [
    "print item.get_wrong_answers().available()\n",
    "print [a.object_map for a in item.get_wrong_answers()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There they are!\n",
    "\n",
    "That's a basic overview of `items`. They are very powerful, and to learn more, you can inspect the `records` directory that came along with this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Assessments\n",
    "\n",
    "Conceptually, `items` are organized into `assessments` -- which are then offered to students. An `assessment` in a classroom might be a homework, a quiz, or an exam ... a tool that evaluates students' knowledge of a topic or outcome.\n",
    "\n",
    "Let's see what `assessments` exist in our `bank`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dlkit.mongo.assessment.objects.AssessmentList object at 0x10e6e4b10>\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print bank.get_assessments()\n",
    "print bank.get_assessments().available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're starting with a clean slate, we have no `assessments`. Let's get a `form`, and create one. Note that with the current `DLKit` configuration, we need to include at least the `simple-child-sequencing` record for each `assessment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dlkit.mongo.assessment.objects.Assessment object at 0x10f688bd0>\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from records.registry import ASSESSMENT_RECORD_TYPES\n",
    "SIMPLE_SEQUENCE_ASSESSMENT = Type(**ASSESSMENT_RECORD_TYPES['simple-child-sequencing'])\n",
    "\n",
    "form = bank.get_assessment_form_for_create([SIMPLE_SEQUENCE_ASSESSMENT])\n",
    "form.display_name = 'Homework #1'\n",
    "form.description = 'Favorites'\n",
    "assessment = bank.create_assessment(form)\n",
    "print assessment\n",
    "print bank.get_assessment_items(assessment.ident).available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our `assessment`, we can add `items` to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "bank.add_item(assessment.ident, item.ident)\n",
    "print bank.get_assessment_items(assessment.ident).available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great for authoring `assessments`, but `DLKit` defines another set of methods to offer the `assessment` in \"student mode\". This is through the `AssessmentSession` -- but first, we need to create an `assessment_offered`. `assessments_offered` wrap some metadata around the canonical `assessment`, like the `start_time`, `deadline`, `duration`, etc. -- all of these typically are optional. Leaving them out \"opens\" the `assessment_offered` to students immediately, and it never \"closes\".\n",
    "\n",
    "Again, we need a `form` for this, and that method requires the `assessment` ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dlkit.mongo.assessment.objects.AssessmentOffered object at 0x10f705f10>\n"
     ]
    }
   ],
   "source": [
    "form = bank.get_assessment_offered_form_for_create(assessment.ident, [])\n",
    "assessment_offered = bank.create_assessment_offered(form)\n",
    "print assessment_offered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have an `assessment_offered`, we can provide a set of methods for students to take the assessment. Each \"taker\" generates an `assessment_taken`, which links their taker ID to the `assessment_offered` ID. The `assessment_taken` also links to an `assessment_section`, which maintains a list of questions and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dlkit.mongo.assessment.objects.AssessmentTaken object at 0x10f5fde50>\n",
      "tutorial_user@school.edu\n"
     ]
    }
   ],
   "source": [
    "form = bank.get_assessment_taken_form_for_create(assessment_offered.ident, [])\n",
    "assessment_taken = bank.create_assessment_taken(form)\n",
    "print assessment_taken\n",
    "print str(assessment_taken.get_taking_agent_id().identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to get the `assessment` questions ... they are the same for our simple `assessment` because there is only one question, but you can easily imagine how the behavior might change when multiple questions are present. For sequential `assessments`, each question must be answered in order. Hence, you iterate through the questions using methods like `get_first_question()` & `get_next_question()` or `get_first_unanswered_question()` & `get_next_unanswered_question()`. Alternatively, if the `assessment` does not specify that the questions must be answered sequentially, you can get all the questions in bulk, via `get_questions()`. In more complex and adaptive scenarios, even this method might be dynamically updated, as students navigate through the `assessment`.\n",
    "\n",
    "`Assessments` can be divided into multiple `assessment_sections`, for example to provide UI separation. In our simple `assessment`, there is only one `assessment_section`, and we'll use that ID to grab the questions.\n",
    "\n",
    "Let's demonstrate the methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assessment.Item%3A58010142cdfc5c3a0bc23b5c%40assessment-session\n",
      "assessment.Item%3A58010142cdfc5c3a0bc23b5c%40assessment-session\n",
      "['assessment.Item%3A58010142cdfc5c3a0bc23b5c%40assessment-session']\n"
     ]
    }
   ],
   "source": [
    "assessment_section = bank.get_first_assessment_section(assessment_taken.ident)\n",
    "print str(bank.get_first_question(assessment_section.ident).ident)\n",
    "print str(bank.get_first_unanswered_question(assessment_section.ident).ident)\n",
    "print [str(q.ident) for q in bank.get_questions(assessment_section.ident)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's interesting to note that this question ID is *different* than the original `item` ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assessment.Item%3A57fe61e8cdfc5c3a0bc23b48%40ODL.MIT.EDU\n"
     ]
    }
   ],
   "source": [
    "print str(item.ident)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because questions, when put into an `assessment_section`, generate new, unique IDs. This helps us manage more advanced `item` and `question` records that manipulate the ID attribute to provide adaptability or consistent randomization -- beyond the scope of this basic tutorial.\n",
    "\n",
    "However, we will use this new question ID to submit a `response`. Again, we'll use a `form`, and we'll supply it with a `choice` ID from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'text': u'blue', u'id': u'57fe61edcdfc5c3a0bc23b49', u'name': u''}, {u'text': u'red', u'id': u'57fe61edcdfc5c3a0bc23b4a', u'name': u''}, {u'text': u'yellow', u'id': u'57fe61edcdfc5c3a0bc23b4b', u'name': u''}]\n",
      "False\n",
      "{u'hour': 16, u'month': 10, u'second': 37, u'microsecond': 495746, u'year': 2016, u'tzinfo': None, u'day': 14, u'minute': 13}\n"
     ]
    }
   ],
   "source": [
    "question = bank.get_first_question(assessment_section.ident)\n",
    "choices = question.get_choices()\n",
    "print choices\n",
    "\n",
    "form = bank.get_response_form(assessment_section.ident, question.ident)\n",
    "form.add_choice_id(choices[1]['id'])\n",
    "bank.submit_response(assessment_section.ident, question.ident, form)\n",
    "response = bank.get_response(assessment_section.ident, question.ident)\n",
    "print response.is_correct()\n",
    "print response.get_submission_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this last method, `is_correct()`, is a non-OSID convenience method, that currently only works with multiple choice questions, but can easily be integrated into any record extension.\n",
    "\n",
    "We can try submitting again, if the `assessment_offered` allows us to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "{u'hour': 16, u'month': 10, u'second': 46, u'microsecond': 957155, u'year': 2016, u'tzinfo': None, u'day': 14, u'minute': 13}\n"
     ]
    }
   ],
   "source": [
    "form = bank.get_response_form(assessment_section.ident, question.ident)\n",
    "form.add_choice_id(choices[0]['id'])\n",
    "bank.submit_response(assessment_section.ident, question.ident, form)\n",
    "response = bank.get_response(assessment_section.ident, question.ident)\n",
    "print response.is_correct()\n",
    "print response.get_submission_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that both submissions are stored in the database, but currently only the most recent one can be retrieved. Time data in `DLKit` is stored as UTC, so the information printed above may differ from your local time.\n",
    "\n",
    "At any time, instructors can get a record of all student `responses` and questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'bankId': u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU', u'displayName': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'description': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'recordTypeIds': [u'answer-record-type%3Amulti-choice%40ODL.MIT.EDU'], u'isCorrect': True, u'choiceIds': [u'57fe61edcdfc5c3a0bc23b49'], u'genusTypeId': 'GenusType%3ADEFAULT%40DLKIT.MIT.EDU', u'assignedBankIds': [u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU'], u'submissionTime': {u'hour': 16, u'month': 10, u'second': 46, u'microsecond': 957155, u'year': 2016, u'tzinfo': None, u'day': 14, u'minute': 13}, 'type': 'Answer', 'id': 'assessment.Answer%3A5801043acdfc5c3a0bc23b61%40ODL.MIT.EDU'}]\n"
     ]
    }
   ],
   "source": [
    "responses = bank.get_assessment_taken_responses(assessment_taken.ident)\n",
    "print [r.object_map for r in responses]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, the results only include the `responses` without regard to `assessment_sections`, but you can easily link in the actual questions as well. Sample code is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'itemId': u'assessment.Item%3A57fe61e8cdfc5c3a0bc23b48%40ODL.MIT.EDU', 'responses': [], u'displayName': {u'text': u'Basic addition question', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'description': {u'text': u'addition question with fruit', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'recordTypeIds': [u'question-record-type%3Amulti-choice-text%40ODL.MIT.EDU'], u'text': {u'text': u'Which color do you prefer?', u'languageTypeId': u'639-2%3AENG%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net', u'scriptTypeId': u'15924%3ALATN%40ISO'}, 'bankId': u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU', u'choices': [{u'text': u'blue', u'id': u'57fe61edcdfc5c3a0bc23b49', u'name': u''}, {u'text': u'red', u'id': u'57fe61edcdfc5c3a0bc23b4a', u'name': u''}, {u'text': u'yellow', u'id': u'57fe61edcdfc5c3a0bc23b4b', u'name': u''}], u'genusTypeId': 'GenusType%3ADEFAULT%40DLKIT.MIT.EDU', u'assignedBankIds': [u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU'], 'type': 'OsidObject', 'id': 'assessment.Item%3A58010142cdfc5c3a0bc23b5c%40assessment-session', u'multiAnswer': False, 'learningObjectiveIds': []}]\n"
     ]
    }
   ],
   "source": [
    "question_maps = []\n",
    "for index, question in enumerate(assessment_section.get_questions()):\n",
    "    question_map = question.object_map\n",
    "    question_map.update({\n",
    "            'itemId': assessment_section._my_map['questions'][index]['itemId'],\n",
    "            'responses': []\n",
    "        })\n",
    "    question_maps.append(question_map)\n",
    "for index, response in enumerate(responses):\n",
    "    question_maps[index]['responses'].append(response.object_map)\n",
    "print question_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we add back in the `itemId` attribute so that we can map the questions that students see (now with all unique IDs) back to the original `items`.\n",
    "\n",
    "But, um...why is the `responses` list empty? Because `OsidLists` are exhaustive -- they are Python generators. So they can only be iterated through once. We can solve that either by converting to a list, or calling the `get_assessment_taken_responses()` method again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'itemId': u'assessment.Item%3A57fe61e8cdfc5c3a0bc23b48%40ODL.MIT.EDU', 'responses': [{'bankId': u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU', u'displayName': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'description': {u'text': u'', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'recordTypeIds': [u'answer-record-type%3Amulti-choice%40ODL.MIT.EDU'], u'isCorrect': True, u'choiceIds': [u'57fe61edcdfc5c3a0bc23b49'], u'genusTypeId': 'GenusType%3ADEFAULT%40DLKIT.MIT.EDU', u'assignedBankIds': [u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU'], u'submissionTime': {u'hour': 16, u'month': 10, u'second': 46, u'microsecond': 957155, u'year': 2016, u'tzinfo': None, u'day': 14, u'minute': 13}, 'type': 'Answer', 'id': 'assessment.Answer%3A5801043acdfc5c3a0bc23b61%40ODL.MIT.EDU'}], u'displayName': {u'text': u'Basic addition question', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'description': {u'text': u'addition question with fruit', u'languageTypeId': '639-2%3AENG%40ISO', u'scriptTypeId': '15924%3ALATN%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net'}, u'recordTypeIds': [u'question-record-type%3Amulti-choice-text%40ODL.MIT.EDU'], u'text': {u'text': u'Which color do you prefer?', u'languageTypeId': u'639-2%3AENG%40ISO', u'formatTypeId': u'TextFormats%3APLAIN%40okapia.net', u'scriptTypeId': u'15924%3ALATN%40ISO'}, 'bankId': u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU', u'choices': [{u'text': u'blue', u'id': u'57fe61edcdfc5c3a0bc23b49', u'name': u''}, {u'text': u'red', u'id': u'57fe61edcdfc5c3a0bc23b4a', u'name': u''}, {u'text': u'yellow', u'id': u'57fe61edcdfc5c3a0bc23b4b', u'name': u''}], u'genusTypeId': 'GenusType%3ADEFAULT%40DLKIT.MIT.EDU', u'assignedBankIds': [u'assessment.Bank%3A57fe54dccdfc5c3a0bc23b47%40ODL.MIT.EDU'], 'type': 'OsidObject', 'id': 'assessment.Item%3A58010142cdfc5c3a0bc23b5c%40assessment-session', u'multiAnswer': False, 'learningObjectiveIds': []}]\n"
     ]
    }
   ],
   "source": [
    "responses_list = list(bank.get_assessment_taken_responses(assessment_taken.ident))\n",
    "responses = bank.get_assessment_taken_responses(assessment_taken.ident)\n",
    "question_maps = []\n",
    "for index, question in enumerate(assessment_section.get_questions()):\n",
    "    question_map = question.object_map\n",
    "    question_map.update({\n",
    "            'itemId': assessment_section._my_map['questions'][index]['itemId'],\n",
    "            'responses': []\n",
    "        })\n",
    "    question_maps.append(question_map)\n",
    "for index, response in enumerate(responses):\n",
    "    question_maps[index]['responses'].append(response.object_map)\n",
    "print question_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you have the basics of the `Assessment` service! Much of the additional complexity appears in the record extensions for various `item` types and `assessment` / `assessment_offered` / `assessment_taken` settings.\n",
    "\n",
    "For example, we have randomized multiple choice questions where the choices appear in different orders to each student, but when students return to the `assessment_taken`, they see the exact same order they've seen before -- randomized per student, not per view of the question.\n",
    "\n",
    "Another example of a complex assessment is adaptive behavior, where the \"next question\" a student sees depends on their response to the previous question. So each students gets a different set of questions, depending on their knowledge and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patterns in DLKit\n",
    "\n",
    "Now that we've gone through the `Assessment` service, you've hopefully learned the basics about catalogs, objects, forms, sessions, and managers. Luckily, these patterns appear across all the `DLKit` services. So you can easily pick up how to use the other services. http://osid.org/ is a good reference, and we've included a simple table below that reflects the services available in this `DLKit` build:\n",
    "\n",
    "````\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "|   Service     |      Catalog     |                            Objects                                     |\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "| Assessment    | Bank             | Item, Assessment, AssessmentOffered, AssessmentTaken, AssessmentPart   |\n",
    "| Authorization | Vault            | Authorization                                                          |\n",
    "| Commenting    | Book             | Comment                                                                |\n",
    "| Grading       | Gradebook        | GradeSystem, GradeEntry, GradebookColumn                               |\n",
    "| Logging       | Log              | LogEntry                                                               |\n",
    "| Repository    | Repository       | Asset, AssetContent                                                    |\n",
    "| Resource      | Bin              | Resource                                                               |\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "````"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
